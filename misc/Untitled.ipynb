{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7554df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f98d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/Spirelab/Desktop/open_day/lab_members'\n",
    "\n",
    "model_dir = 'C:/Users/Spirelab/Desktop/open_day/saved_model'\n",
    "\n",
    "os.chdir(dir)\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "audiofile = files[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc12d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_classification(audio):\n",
    "    \n",
    "    #print(audio.shape)\n",
    "    \n",
    "    y,fs = librosa.load(audio, sr = 16000)\n",
    "\n",
    "    \n",
    "    mfcc_full = np.array(np.transpose(librosa.feature.mfcc(y , sr = fs , n_mfcc = 13 , n_fft = 320 , win_length = 320 , hop_length = 160)))\n",
    "\n",
    "    mfcc_df = pd.DataFrame(mfcc_full , columns = ['F0' , 'F1' , 'F2' , 'F3' , 'F4' , 'F5' , 'F6' , 'F7' , 'F8' , 'F9' , 'F10' , 'F11' , 'F12'])\n",
    "\n",
    "    mfcc_mean = np.array(np.transpose(mfcc_df[['F0','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12']].mean())).reshape(1,-1)\n",
    "\n",
    "    mfcc_median = np.array(mfcc_df[['F0','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12']].median()).reshape(1,-1)\n",
    "\n",
    "    mfcc_floor = np.array(mfcc_df[['F0','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12']].apply(np.floor))\n",
    "\n",
    "    mfcc_mode = stats.mode(mfcc_floor)[0].T.reshape(1,-1)\n",
    "\n",
    "    mfcc_std = np.array(mfcc_df[['F0','F1','F2','F3','F4','F5','F6','F7','F8','F9','F10','F11','F12']].std()).reshape(1,-1)\n",
    "\n",
    "    mfcc_stats = np.hstack((mfcc_mean, mfcc_median, mfcc_mode, mfcc_std))\n",
    "\n",
    "    os.chdir(model_dir)\n",
    "\n",
    "    json_file = open('model_2023_02_28_17_29.json' , 'r')\n",
    "\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "    json_file.close()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "    loaded_model.load_weights(\"model_weights_2023_02_28_17_29.h5\")\n",
    "\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    prediction = loaded_model.predict(mfcc_stats)\n",
    "\n",
    "    if prediction > 0.3:\n",
    "    \n",
    "        gender = 'Gender is Female'\n",
    "\n",
    "    else:\n",
    "    \n",
    "        gender = 'Gender is Male'\n",
    "    \n",
    "    return(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fd5713",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mfcc() takes 0 positional arguments but 1 positional argument (and 2 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4024\\795033467.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgender_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4024\\86484714.py\u001b[0m in \u001b[0;36mgender_classification\u001b[1;34m(audio)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmfcc_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m320\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mwin_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m320\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m160\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmfcc_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc_full\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'F0'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F1'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F2'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F3'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F4'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F5'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F6'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F7'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F8'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F9'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F10'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F11'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'F12'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mfcc() takes 0 positional arguments but 1 positional argument (and 2 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "gender = gender_classification(audiofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff275174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
